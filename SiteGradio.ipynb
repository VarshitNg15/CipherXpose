{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import joblib\n",
        "from scipy.stats import kurtosis, skew\n",
        "import traceback\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the trained models and preprocessing tools\n",
        "try:\n",
        "    hash_model = load_model('/content/drive/My Drive/hash_model/hashing_algorithm_cnn_model.h5')\n",
        "    hash_scaler = joblib.load('/content/drive/My Drive/hash_model/scaler.pkl')\n",
        "    hash_label_encoder = joblib.load('/content/drive/My Drive/hash_model/label_encoder.pkl')\n",
        "\n",
        "    stream_model = load_model('/content/drive/My Drive/stream_model/stream_algorithm_cnn_model.h5')\n",
        "    stream_scaler = joblib.load('/content/drive/My Drive/stream_model/scaler.pkl')\n",
        "    stream_label_encoder = joblib.load('/content/drive/My Drive/stream_model/label_encoder.pkl')\n",
        "\n",
        "    block_model = load_model('/content/drive/My Drive/block_model/block_algorithm_cnn_model.h5')\n",
        "    block_scaler = joblib.load('/content/drive/My Drive/block_model/scaler.pkl')\n",
        "    block_label_encoder = joblib.load('/content/drive/My Drive/block_model/label_encoder.pkl')\n",
        "except Exception as e:\n",
        "    print(\"Error loading models or preprocessing tools.\")\n",
        "    print(e)\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Function to extract features and detect weaknesses from the input text\n",
        "def extract_features(cipher_text):\n",
        "    try:\n",
        "        cipher_bytes = bytes.fromhex(cipher_text)\n",
        "        cipher_array = np.frombuffer(cipher_bytes, dtype=np.uint8)\n",
        "\n",
        "        mean = np.mean(cipher_array)\n",
        "        std_dev = np.std(cipher_array)\n",
        "\n",
        "        # Histogram for entropy calculation\n",
        "        histogram, _ = np.histogram(cipher_array, bins=256, range=(0, 256))\n",
        "        histogram = histogram / np.sum(histogram)  # Normalize histogram\n",
        "        entropy = -np.sum(histogram * np.log2(histogram + 1e-10))\n",
        "\n",
        "        kurt = kurtosis(cipher_array)\n",
        "        skewness = skew(cipher_array)\n",
        "\n",
        "        min_value = np.min(cipher_array)\n",
        "        max_value = np.max(cipher_array)\n",
        "        range_value = max_value - min_value\n",
        "        unique_byte_count = len(np.unique(cipher_array))\n",
        "\n",
        "        # Combine features into a single list\n",
        "        features = [\n",
        "            mean, std_dev, entropy, kurt, skewness, min_value, max_value, range_value, unique_byte_count\n",
        "        ]\n",
        "\n",
        "        # Define ideal ranges for each feature\n",
        "        ideal_entropy = \"7.5 to 8.0\"  # Ideal entropy range for secure ciphertext\n",
        "        ideal_skewness = \"close to 0\"  # Ideal skewness should be near zero for randomness\n",
        "        ideal_kurtosis = \"around 3.0\"  # Ideal kurtosis for a normal distribution\n",
        "        ideal_unique_byte_count = \"above 200\"  # Ideal count for a diverse byte range\n",
        "\n",
        "        # Detect weaknesses with detailed explanations\n",
        "        weakness_messages = []\n",
        "\n",
        "        if entropy < 7.5:\n",
        "            weakness_messages.append(\n",
        "                f\"Low entropy detected ({entropy:.2f}). Ideal range: {ideal_entropy}. \"\n",
        "                \"This indicates insufficient randomness, making the ciphertext potentially susceptible to cryptanalysis.\"\n",
        "            )\n",
        "        elif entropy > 8.0:\n",
        "            weakness_messages.append(\n",
        "                f\"High entropy detected ({entropy:.2f}). Ideal range: {ideal_entropy}. \"\n",
        "                \"This could indicate excessive noise or incorrect encryption.\"\n",
        "            )\n",
        "\n",
        "        if kurt < 2.0 or kurt > 4.0:\n",
        "            weakness_messages.append(\n",
        "                f\"Unusual kurtosis detected ({kurt:.2f}). Ideal value: {ideal_kurtosis}. \"\n",
        "                \"This suggests that the byte distribution may be irregular, which can indicate poor randomness.\"\n",
        "            )\n",
        "\n",
        "        if abs(skewness) > 0.5:\n",
        "            weakness_messages.append(\n",
        "                f\"High skewness detected ({skewness:.2f}). Ideal range: {ideal_skewness}. \"\n",
        "                \"A skewed distribution indicates that certain byte values occur more frequently, reducing the ciphertext's randomness.\"\n",
        "            )\n",
        "\n",
        "        if unique_byte_count < 200:\n",
        "            weakness_messages.append(\n",
        "                f\"Low unique byte count detected ({unique_byte_count}). Ideal value: {ideal_unique_byte_count}. \"\n",
        "                \"A low number of unique byte values suggests that the encryption algorithm might not be using the full byte range effectively, leading to patterns.\"\n",
        "            )\n",
        "\n",
        "        return features, weakness_messages\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error extracting features from input.\")\n",
        "        print(e)\n",
        "        traceback.print_exc()\n",
        "        return None, [\"Error extracting features from input.\"]\n",
        "\n",
        "# Function to preprocess and predict using a specified model\n",
        "def predict(model, scaler, label_encoder, cipher_text):\n",
        "    features, weaknesses = extract_features(cipher_text)\n",
        "    if features is None:\n",
        "        return None, \"Error extracting features from input text.\", weaknesses\n",
        "\n",
        "    try:\n",
        "        features = np.array(features).reshape(1, -1)  # Reshape for scaling\n",
        "        features = scaler.transform(features)  # Scale features\n",
        "        features = features.reshape(1, 9, 1, 1)  # Reshape for CNN (assuming single-channel images)\n",
        "\n",
        "        # Predict using the model\n",
        "        prediction = model.predict(features)\n",
        "        confidence = prediction.max()\n",
        "        predicted_label_index = np.argmax(prediction, axis=1)\n",
        "        predicted_label = label_encoder.inverse_transform(predicted_label_index)[0]\n",
        "\n",
        "        return confidence, predicted_label, weaknesses\n",
        "    except Exception as e:\n",
        "        print(\"Error in prediction process.\")\n",
        "        print(e)\n",
        "        traceback.print_exc()\n",
        "        return None, \"Prediction failed.\", weaknesses\n",
        "\n",
        "# Define the function that integrates with Gradio\n",
        "def predict_algorithm(cipher_text):\n",
        "    hash_confidence, hash_prediction, hash_weaknesses = predict(hash_model, hash_scaler, hash_label_encoder, cipher_text)\n",
        "    stream_confidence, stream_prediction, stream_weaknesses = predict(stream_model, stream_scaler, stream_label_encoder, cipher_text)\n",
        "    block_confidence, block_prediction, block_weaknesses = predict(block_model, block_scaler, block_label_encoder, cipher_text)\n",
        "\n",
        "    # Find the prediction with the highest confidence score\n",
        "    confidences = [hash_confidence, stream_confidence, block_confidence]\n",
        "    predictions = [hash_prediction, stream_prediction, block_prediction]\n",
        "\n",
        "    if None in confidences:\n",
        "        return \"An error occurred during prediction.\"\n",
        "\n",
        "    # Identify the prediction with the highest confidence score\n",
        "    max_index = np.argmax(confidences)\n",
        "    prediction = predictions[max_index]\n",
        "\n",
        "    # Combine weaknesses from all models\n",
        "    all_weaknesses = set(hash_weaknesses + stream_weaknesses + block_weaknesses)\n",
        "    weakness_output = \"\\n\".join(all_weaknesses) if all_weaknesses else \"No significant weaknesses detected.\"\n",
        "\n",
        "    # Create an informative output string, listing all confidence values\n",
        "    result = (\n",
        "        f\"Predicted Algorithm: {prediction}\\n\\n\"\n",
        "        f\"Confidence Scores:\\n\"\n",
        "        f\" - Hashing Model: {hash_confidence:.4f} ({hash_prediction})\\n\"\n",
        "        f\" - Stream Cipher Model: {stream_confidence:.4f} ({stream_prediction})\\n\"\n",
        "        f\" - Block Cipher Model: {block_confidence:.4f} ({block_prediction})\\n\\n\"\n",
        "        f\"Weakness Detection:\\n{weakness_output}\"\n",
        "    )\n",
        "\n",
        "    return result\n",
        "\n",
        "# Update the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_algorithm,\n",
        "    inputs=gr.Textbox(label=\"Enter Cipher Text (Hexadecimal)\"),\n",
        "    outputs=gr.Textbox(label=\"Predicted Algorithm, Confidence Scores, and Weakness Detection\"),\n",
        "    title=\"CipherXPose: Cryptographic Algorithm and Weakness Detection\",\n",
        "    description=\"This tool predicts which cryptographic algorithm is most likely used for the provided cipher text and detects potential weaknesses in the encryption.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SNoY1Wl3sBN",
        "outputId": "5d1a7fcd-8daf-4757-a9ee-5889cbdae268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802ms/step\n",
            "Predicted Algorithm (Majority Vote): RC4\n",
            "\n",
            "Model Predictions:\n",
            " - Stream Cipher Model: RC4 (Confidence: 0.9995)\n",
            " - Hash Model: SHA256 (Confidence: 0.9995)\n",
            " - Block Cipher Model: 3DES (Confidence: 0.4679)\n"
          ]
        }
      ]
    }
  ]
}